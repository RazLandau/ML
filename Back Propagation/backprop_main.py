import backprop_dataimport matplotlib.pyplot as pltimport backprop_networkimport numpy as npdef plot(values, data, param):    plt.plot([i+1 for i in range(len(values))], values)    plt.xlabel("epochs")    plt.ylabel(param)    plt.title(data + " " + param)    plt.savefig("q2b_" + data + "-" + param + ".png")    plt.close()def q2b():    training_data, test_data = backprop_data.load(train_size=10000,test_size=5000)    net = backprop_network.Network([784, 40, 10])    test_accuracies, train_accuracies, train_loss = net.SGD(        training_data,        epochs=30,        mini_batch_size=10,        learning_rate=0.1,        test_data=test_data,        calc_train_stats=True    )    plot(test_accuracies, "test", "accuracy")    plot(train_accuracies, "train", "accuracy")    plot(train_loss, "train", "loss")def q2c():    training_data, test_data = backprop_data.load(train_size=50000, test_size=10000)    net = backprop_network.Network([784, 40, 10])    test_acc = net.SGD(training_data, epochs=30, mini_batch_size=10, learning_rate=0.1, test_data=test_data)[0]    print("q3:", test_acc[-1])def q2d():    training_data, test_data = backprop_data.load(train_size=10000, test_size=5000)    net = backprop_network.Network([784, 30, 30, 30, 30, 10])    gradient_norms = net.SGD(training_data, epochs=30, mini_batch_size=10000, learning_rate=0.1,            test_data=test_data, calc_gradient_norms=True)[3]    fig = plt.figure()    ax = fig.add_subplot(1, 1, 1)    for i in range(np.asarray(gradient_norms).shape[1]):        ax.plot(np.asarray(gradient_norms)[:, i], label="layer " + str(i))    ax.legend()    plt.savefig("q2d.png")    plt.close()def main():    q2b()    q2c()    q2d()if __name__ == '__main__':    main()